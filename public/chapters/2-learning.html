<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 2: Neurons That Learn ‚Äî MiniLLM</title>
  <link rel="stylesheet" href="/css/style.css">
</head>
<body data-chapter="2">
  <nav class="chapter-nav">
    <a href="/">‚Üê Home</a>
    <a href="/chapters/1-neuron.html">‚Üê Prev</a>
    <span class="nav-title">Chapter 2: Learning</span>
    <a href="/chapters/3-layers.html">Next ‚Üí</a>
  </nav>
  <div class="chapter-content">
    <div class="chapter-header fade-in-up">
      <div class="chapter-number">Chapter 2</div>
      <h1>Neurons That Learn</h1>
      <p>In Chapter 1, you manually set the weight and bias by hand. That was fun, but imagine doing that for a network with <em>billions</em> of weights. Impossible! In this chapter, we'll discover how neurons figure out the right weights <strong>on their own</strong> ‚Äî by learning from examples.</p>
    </div>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <!-- SECTION 1: What is Training?                -->
    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <div class="section fade-in-up delay-1">
      <h2>üé∏ What Does "Training" Mean?</h2>

      <p>Have you ever tuned a guitar? You pluck a string, listen to the sound, and then turn the tuning peg a tiny bit. Pluck again ‚Äî closer? Turn a little more. You keep repeating this cycle until the note sounds right. You never calculate the exact position of the peg with a formula ‚Äî you just <strong>listen and adjust</strong>.</p>

      <p><strong>Training</strong> a neural network works the same way. We show the network an example (like an input-output pair), let it make a prediction, check how wrong it was, and then nudge the weights slightly to make it less wrong. Then we do it again. And again. Thousands of times. Each time, the network gets a tiny bit better.</p>

      <p>But to do this, we need a way to measure "how wrong" the network is. That measurement has a name: <strong>loss</strong>.</p>

      <h3>üìä What is Loss?</h3>

      <p><strong>Loss</strong> is a single number that tells you how wrong the network's predictions are. Think of it like a score in golf: <strong>lower is better</strong>. A loss of 0 means the network is perfect ‚Äî every prediction exactly matches the correct answer. A high loss means the network is way off.</p>

      <p>For example, if the correct answer is 1.0 and the network predicts 0.3, the loss captures that gap. The specific formula we'll use is called <strong>Mean Squared Error (MSE)</strong> ‚Äî it takes the difference between the prediction and the correct answer, squares it (so negative errors and positive errors both count), and averages across all examples. But you don't need to memorize that. Just remember: <strong>loss = how wrong we are. Lower is better.</strong></p>

      <h3>üîÑ What is an Epoch?</h3>

      <p>When the network looks at <em>every single training example once</em>, that's called one <strong>epoch</strong> (pronounced "EP-ock"). If you have 4 training examples and the network sees all 4, that's 1 epoch. If it sees all 4 again, that's 2 epochs. Training usually takes hundreds or thousands of epochs ‚Äî each pass through the data makes the network a little bit smarter.</p>

      <p>Think of epochs like laps around a track. One lap = one epoch. The more laps you run, the more fit you get (up to a point). Similarly, the more epochs you train, the lower the loss goes ‚Äî the network keeps getting better.</p>
    </div>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <!-- SECTION 2: How Learning Works Step by Step  -->
    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <div class="section fade-in-up">
      <h2>üß© How Learning Works: Step by Step</h2>

      <p>Let's walk through exactly what happens during one training step. There are 5 stages, and they repeat over and over:</p>

      <ol>
        <li>
          <strong>Forward Pass:</strong> Feed an input into the network and let it calculate an output. This is exactly what you did in Chapter 1 ‚Äî input goes in, gets multiplied by weights, bias gets added, sigmoid squishes the result. The network makes its best guess.
        </li>
        <li>
          <strong>Calculate the Loss:</strong> Compare the network's guess to the correct answer. How far off was it? This gives us the loss ‚Äî one number summarizing the error.
        </li>
        <li>
          <strong>Backpropagation:</strong> This is the clever part. The network works <em>backwards</em> from the loss to figure out which weights were most responsible for the error. It's like tracing a wrong answer on a test back to the specific thing you misunderstood. The term <strong>backpropagation</strong> (or "backprop" for short) literally means "propagating the error backward" through the network.
        </li>
        <li>
          <strong>Update the Weights:</strong> Now that we know which weights caused the error, we nudge them in the direction that would reduce the loss. Big error ‚Üí bigger nudge. Small error ‚Üí tiny nudge. The size of the nudge is controlled by a setting called the <strong>learning rate</strong> (more on that below).
        </li>
        <li>
          <strong>Repeat:</strong> Do it all again with the next example. After one full pass through all examples (one epoch), the network is a little smarter. After hundreds of epochs, it can be remarkably accurate.
        </li>
      </ol>

      <p>This cycle ‚Äî forward, measure error, trace backwards, adjust, repeat ‚Äî is the heartbeat of all machine learning. Every AI you've ever used was trained this way, including ChatGPT.</p>
    </div>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <!-- SECTION 3: Gradient Descent visualization   -->
    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <div class="section fade-in-up delay-1">
      <h2>üìâ Gradient Descent: Rolling Downhill</h2>

      <p>Here's a beautiful way to visualize training. Imagine that we plot the loss (how wrong the network is) as a landscape of hills and valleys. The height of the landscape at any point represents the loss for a particular weight value. Our goal is to find the <strong>lowest valley</strong> ‚Äî the weight that gives the smallest loss.</p>

      <p><strong>Gradient descent</strong> is the algorithm that finds that valley. It works by dropping a ball onto the landscape and letting gravity do the work. The ball rolls downhill, always moving toward lower loss. The <strong>gradient</strong> is just a fancy word for "which direction is downhill" ‚Äî it tells the ball which way to roll.</p>

      <p>The <strong>learning rate</strong> controls how big each step is. A small learning rate means the ball takes tiny, careful steps (slow but precise). A large learning rate means big, bold leaps (fast but might overshoot the valley and bounce around). Try adjusting the learning rate slider below and see the difference!</p>

      <p><strong>Try this:</strong> Click "Drop the Ball" and watch it roll to the bottom. Then reset, crank the learning rate up to 0.5, and drop again ‚Äî see how it behaves differently?</p>

      <div class="interactive-area">
        <canvas id="loss-canvas" width="600" height="300"></canvas>
        <div class="controls">
          <button class="btn btn-primary btn-sm" id="drop-btn">üé± Drop the Ball</button>
          <button class="btn btn-secondary btn-sm" id="reset-ball-btn">Reset</button>
          <div class="control-group">
            <label>Learning Rate</label>
            <input type="range" id="ball-lr" min="0.01" max="0.5" step="0.01" value="0.1" style="width:100px;">
            <span class="slider-value" id="ball-lr-val">0.10</span>
          </div>
        </div>
        <div class="narration" id="ball-narration">Click "Drop the Ball" to watch gradient descent find the minimum!</div>
      </div>

      <p>What you just saw is the core of how every neural network learns. The ball finding the valley is the network finding the best weights. In real networks, the landscape has millions of dimensions (one per weight) instead of just one ‚Äî but the principle is identical: follow the slope downhill.</p>
    </div>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <!-- SECTION 4: AND gate training                -->
    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <div class="section fade-in-up delay-2">
      <h2>üéØ Activity: Train on the AND Gate</h2>

      <p>Let's put this all together and watch a neuron <strong>actually learn</strong>. We'll train it on a classic problem: the <strong>AND gate</strong>.</p>

      <p>An AND gate is a simple rule: the output is <strong>1 only when both inputs are 1</strong>. Here are all 4 possible input combinations:</p>

      <ul>
        <li><strong>[0, 0] ‚Üí 0</strong> (neither is 1, so output is 0)</li>
        <li><strong>[0, 1] ‚Üí 0</strong> (only one is 1, so output is 0)</li>
        <li><strong>[1, 0] ‚Üí 0</strong> (only one is 1, so output is 0)</li>
        <li><strong>[1, 1] ‚Üí 1</strong> (both are 1, so output is 1! ‚úÖ)</li>
      </ul>

      <p>Our neuron starts with random weights ‚Äî it has no idea what the AND gate is. Then we train it: show it the 4 examples over and over, and let gradient descent adjust the weights to minimize the loss. After enough epochs, the neuron should <em>figure out</em> the AND gate on its own!</p>

      <h3>üó∫Ô∏è Reading the Decision Boundary</h3>

      <p>On the left below, you'll see a colorful 2D grid. Here's how to read it:</p>

      <ul>
        <li>The <strong>purple/dark regions</strong> are where the neuron outputs a value close to <strong>1</strong> (it's saying "yes, this is AND").</li>
        <li>The <strong>light/bright regions</strong> are where the neuron outputs a value close to <strong>0</strong> (it's saying "no").</li>
        <li>The <strong>4 dots</strong> represent the 4 input combinations: (0,0), (0,1), (1,0), and (1,1). Each dot shows the neuron's current prediction.</li>
        <li>As training progresses, you should see the purple region shift so that <strong>only the (1,1) dot ends up in the purple zone</strong> ‚Äî that means the neuron learned the AND gate!</li>
      </ul>

      <h3>üìà Reading the Loss Chart</h3>

      <p>On the right, you'll see a chart that tracks the loss over time:</p>

      <ul>
        <li><strong>X axis = Epoch</strong> (training round number). Each tick is one pass through all 4 examples.</li>
        <li><strong>Y axis = Loss</strong> (error). How wrong the network is overall. Remember: lower is better!</li>
        <li>You should see the line <strong>drop from high to low</strong> as training progresses ‚Äî that's the network getting smarter!</li>
      </ul>

      <p>Try clicking <strong>Train</strong> and watch both visualizations update in real time. You can also try changing the <strong>learning rate</strong> ‚Äî a higher rate makes training faster but can be unstable. A lower rate is safer but slower.</p>

      <div class="interactive-area">
        <div class="grid-2">
          <div>
            <canvas id="and-canvas" width="400" height="300"></canvas>
            <div class="stats">
              <div class="stat"><div class="stat-value" id="and-epoch">0</div><div class="stat-label">Epoch</div></div>
              <div class="stat"><div class="stat-value" id="and-loss">‚Äî</div><div class="stat-label">Loss</div></div>
              <div class="stat"><div class="stat-value" id="and-w1">‚Äî</div><div class="stat-label">Weight 1</div></div>
              <div class="stat"><div class="stat-value" id="and-w2">‚Äî</div><div class="stat-label">Weight 2</div></div>
              <div class="stat"><div class="stat-value" id="and-b">‚Äî</div><div class="stat-label">Bias</div></div>
            </div>
          </div>
          <div>
            <p style="margin:0 0 8px 0; font-size:0.9em; opacity:0.7; text-align:center;"><strong>Loss over time</strong> ‚Äî X: epoch (training round) ¬∑ Y: loss (error)</p>
            <canvas id="and-loss-chart" width="400" height="200"></canvas>
            <div id="and-outputs" class="narration" style="margin-top:12px;">Press Train to begin.</div>
          </div>
        </div>
        <div class="controls">
          <button class="btn btn-primary btn-sm" id="train-and-btn">‚ñ∂ Train</button>
          <button class="btn btn-secondary btn-sm" id="reset-and-btn">Reset</button>
          <div class="control-group">
            <label>Learning Rate</label>
            <input type="range" id="and-lr" min="0.1" max="5" step="0.1" value="2" style="width:100px;">
            <span class="slider-value" id="and-lr-val">2.0</span>
          </div>
        </div>
      </div>

      <p>After training completes, look at the final weights. You should see both weights are <strong>positive</strong> (meaning the neuron cares about both inputs) and the bias is <strong>negative</strong> (meaning the neuron's default answer is "no" ‚Äî it only says "yes" when both inputs push hard enough to overcome the negative bias). That's the AND gate, learned from scratch!</p>
    </div>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <!-- SECTION 5: What just happened?              -->
    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <div class="section fade-in-up">
      <h2>ü§Ø What Just Happened?</h2>

      <p>Let's step back and appreciate what you just witnessed. You took a neuron that started with <strong>completely random weights</strong> ‚Äî it had no idea what an AND gate was. Then you clicked "Train," and the neuron <em>figured it out by itself</em> through nothing more than looking at examples and adjusting its weights to reduce error.</p>

      <p>No one told the neuron "make weight 1 positive" or "set the bias to -5." It discovered those values on its own through gradient descent. <strong>That's machine learning.</strong></p>

      <p>Now scale this up: instead of 2 inputs and 1 neuron, imagine millions of neurons with billions of connections, trained on trillions of words from the internet. The same process ‚Äî forward pass, calculate loss, backpropagate, update weights, repeat ‚Äî is how ChatGPT learned to write, reason, and have conversations.</p>

      <p style="text-align:center; padding:20px; background:rgba(139,92,246,0.06); border-radius:12px; margin-top:16px;">
        <strong>üîë The key insight:</strong> Neural networks aren't programmed with rules.<br>
        They <em>learn</em> patterns from examples, one tiny weight adjustment at a time.<br>
        <span style="opacity:0.7;">Next up: what happens when we connect many neurons in layers?</span>
      </p>
    </div>
  </div>

  <script src="/js/particles.js"></script>
  <script src="/js/neural-engine.js"></script>
  <script src="/js/viz.js"></script>
  <script src="/js/nav.js"></script>
  <script>
    const ps = new ParticleSystem(); ps.start();
    const $ = id => document.getElementById(id);

    // ‚îÄ‚îÄ Loss landscape ball ‚îÄ‚îÄ
    const lossCanvas = $('loss-canvas');
    const lossCtx = lossCanvas.getContext('2d');
    let ballX = Math.random() * 4 + 1; // Start somewhere on the curve
    let ballAnimating = false;
    let ballLr = 0.1;

    // Simple quadratic loss: L(w) = (w - 3)^2 + 0.5*sin(w*3)*2 + 1
    function lossFn(w) {
      return (w - 3) * (w - 3) + Math.sin(w * 2) * 1.5 + 2;
    }
    function lossGrad(w) {
      return 2 * (w - 3) + Math.cos(w * 2) * 3;
    }

    function drawLossLandscape() {
      const w = lossCanvas.width, h = lossCanvas.height;
      lossCtx.clearRect(0, 0, w, h);

      // Draw landscape
      const xMin = -1, xMax = 7;
      const samples = [];
      for (let i = 0; i <= w; i++) {
        const x = xMin + (i / w) * (xMax - xMin);
        samples.push({ x: i, y: lossFn(x) });
      }
      const maxY = Math.max(...samples.map(s => s.y));
      const minY = Math.min(...samples.map(s => s.y));
      const padding = 40;

      // Fill gradient under curve
      lossCtx.beginPath();
      lossCtx.moveTo(0, h);
      for (const s of samples) {
        const py = padding + (1 - (s.y - minY) / (maxY - minY + 1)) * (h - padding * 2);
        lossCtx.lineTo(s.x, py);
      }
      lossCtx.lineTo(w, h);
      const grad = lossCtx.createLinearGradient(0, 0, 0, h);
      grad.addColorStop(0, 'rgba(139, 92, 246, 0.15)');
      grad.addColorStop(1, 'rgba(139, 92, 246, 0.02)');
      lossCtx.fillStyle = grad;
      lossCtx.fill();

      // Draw curve
      lossCtx.beginPath();
      for (let i = 0; i <= w; i++) {
        const py = padding + (1 - (samples[i].y - minY) / (maxY - minY + 1)) * (h - padding * 2);
        if (i === 0) lossCtx.moveTo(i, py); else lossCtx.lineTo(i, py);
      }
      lossCtx.strokeStyle = Viz.colors.purple;
      lossCtx.lineWidth = 3;
      lossCtx.stroke();

      // Ball
      const ballPx = ((ballX - xMin) / (xMax - xMin)) * w;
      const ballPy = padding + (1 - (lossFn(ballX) - minY) / (maxY - minY + 1)) * (h - padding * 2);
      lossCtx.beginPath();
      lossCtx.arc(ballPx, ballPy, 10, 0, Math.PI * 2);
      lossCtx.fillStyle = Viz.colors.orange;
      lossCtx.fill();
      lossCtx.strokeStyle = '#fff';
      lossCtx.lineWidth = 2;
      lossCtx.stroke();

      // Labels
      lossCtx.fillStyle = Viz.colors.textLight;
      lossCtx.font = '11px Inter, sans-serif';
      lossCtx.textAlign = 'center';
      lossCtx.fillText('Weight value ‚Üí', w / 2, h - 5);
      lossCtx.save();
      lossCtx.translate(12, h / 2);
      lossCtx.rotate(-Math.PI / 2);
      lossCtx.fillText('Loss (error) ‚Üí', 0, 0);
      lossCtx.restore();
    }

    function animateBall() {
      if (!ballAnimating) return;
      const grad = lossGrad(ballX);
      ballX -= ballLr * grad * 0.05;
      ballX = Math.max(-0.5, Math.min(6.5, ballX));
      drawLossLandscape();

      const loss = lossFn(ballX);
      $('ball-narration').innerHTML = `Ball at weight = <strong>${ballX.toFixed(3)}</strong>, loss = <strong>${loss.toFixed(3)}</strong>. Gradient = ${grad.toFixed(3)}. ${Math.abs(grad) < 0.1 ? 'üéØ Found a minimum!' : 'Still rolling...'}`;

      if (Math.abs(grad) < 0.05) {
        ballAnimating = false;
        $('ball-narration').innerHTML += ' <strong>Converged!</strong>';
        return;
      }
      requestAnimationFrame(animateBall);
    }

    $('drop-btn').addEventListener('click', () => {
      if (ballAnimating) return;
      ballLr = parseFloat($('ball-lr').value);
      ballAnimating = true;
      animateBall();
    });

    $('reset-ball-btn').addEventListener('click', () => {
      ballAnimating = false;
      ballX = Math.random() * 5 + 0.5;
      drawLossLandscape();
      $('ball-narration').textContent = 'Ball reset! Click "Drop the Ball" again.';
    });

    $('ball-lr').addEventListener('input', () => {
      ballLr = parseFloat($('ball-lr').value);
      $('ball-lr-val').textContent = ballLr.toFixed(2);
    });

    drawLossLandscape();

    // ‚îÄ‚îÄ AND gate training ‚îÄ‚îÄ
    const andData = [
      { input: [0, 0], target: [0] },
      { input: [0, 1], target: [0] },
      { input: [1, 0], target: [0] },
      { input: [1, 1], target: [1] }
    ];

    let andNet = new NeuralEngine.NeuralNetwork([2, 1], 'sigmoid', 'sigmoid');
    let andHistory = [];
    let andTraining = false;
    let andAnimId = null;

    const andCanvas = $('and-canvas');
    const andCtx = andCanvas.getContext('2d');
    const andLossCanvas = $('and-loss-chart');
    const andLossCtx = andLossCanvas.getContext('2d');

    function drawAndViz() {
      const w = andCanvas.width, h = andCanvas.height;
      andCtx.clearRect(0, 0, w, h);

      // Decision boundary (2x2 grid mapped to canvas)
      const res = 40;
      const grid = andNet.classifyGrid(res, -0.5, 1.5, -0.5, 1.5);
      Viz.drawDecisionBoundary(andCtx, grid, res, w, h);

      // Data points
      Viz.drawDataPoints(andCtx, andData, w, h, [-0.5, 1.5, -0.5, 1.5]);

      // Labels for data points
      andCtx.font = '11px Inter, sans-serif';
      andCtx.textAlign = 'left';
      for (const pt of andData) {
        const px = ((pt.input[0] + 0.5) / 2) * w;
        const py = ((pt.input[1] + 0.5) / 2) * h;
        const out = andNet.forward(pt.input)[0];
        andCtx.fillStyle = Viz.colors.text;
        andCtx.fillText(`${out.toFixed(2)}`, px + 8, py - 2);
      }

      // Loss chart
      Viz.drawLossChart(andLossCtx, andHistory, andLossCanvas.width, andLossCanvas.height);

      // Stats
      const layer = andNet.layers[0];
      $('and-epoch').textContent = andNet.epoch;
      $('and-loss').textContent = andNet.loss === Infinity ? '‚Äî' : andNet.loss.toFixed(5);
      $('and-w1').textContent = layer.weights[0][0].toFixed(3);
      $('and-w2').textContent = layer.weights[0][1].toFixed(3);
      $('and-b').textContent = layer.biases[0].toFixed(3);

      // Outputs
      const outs = andData.map(d => {
        const o = andNet.forward(d.input)[0];
        const correct = Math.abs(o - d.target[0]) < 0.3;
        return `[${d.input}]‚Üí${o.toFixed(2)} ${correct ? '‚úÖ' : '‚ùå'}`;
      });
      $('and-outputs').innerHTML = outs.join(' &nbsp;|&nbsp; ');
    }

    function trainAndStep() {
      if (!andTraining) return;
      const lr = parseFloat($('and-lr').value);
      for (let i = 0; i < 5; i++) {
        const loss = andNet.trainBatch(andData, lr, 'mse');
        andHistory.push(loss);
      }
      drawAndViz();

      // Check convergence
      const allCorrect = andData.every(d => {
        const o = andNet.forward(d.input)[0];
        return Math.abs(o - d.target[0]) < 0.2;
      });

      if (allCorrect && andNet.epoch > 20) {
        andTraining = false;
        $('train-and-btn').textContent = '‚ñ∂ Train';
        $('and-outputs').innerHTML += ' &nbsp;<strong>üéâ Learned the AND gate!</strong>';
        Nav.setCompleted(2);
        return;
      }

      if (andNet.epoch < 2000) {
        andAnimId = requestAnimationFrame(trainAndStep);
      } else {
        andTraining = false;
        $('train-and-btn').textContent = '‚ñ∂ Train';
      }
    }

    $('train-and-btn').addEventListener('click', () => {
      andTraining = !andTraining;
      $('train-and-btn').textContent = andTraining ? '‚è∏ Pause' : '‚ñ∂ Train';
      if (andTraining) trainAndStep();
    });

    $('reset-and-btn').addEventListener('click', () => {
      andTraining = false;
      if (andAnimId) cancelAnimationFrame(andAnimId);
      andNet = new NeuralEngine.NeuralNetwork([2, 1], 'sigmoid', 'sigmoid');
      andHistory = [];
      $('train-and-btn').textContent = '‚ñ∂ Train';
      drawAndViz();
    });

    $('and-lr').addEventListener('input', () => {
      $('and-lr-val').textContent = parseFloat($('and-lr').value).toFixed(1);
    });

    drawAndViz();
  </script>
</body>
</html>
